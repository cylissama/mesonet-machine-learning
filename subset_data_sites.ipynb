{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# load RFSM and CRRL data from google drive folder, Carroll & Breathitt County\n",
    "# subset the data based on TAIR, VT90, SM02, PRES\n",
    "# for the RFSM dataset, I have removed the SM02 feature as it is absent from the subset data\n",
    "import pandas as pd\n",
    "\n",
    "CRRL_file = '../CRRL.csv'\n",
    "\n",
    "CRRL_df = pd.read_csv(CRRL_file)\n",
    "\n",
    "print(CRRL_df.head())\n",
    "\n",
    "target_vars = ['TAIR','VT90','SM02','PRES']\n",
    "\n",
    "nan_rows = CRRL_df[CRRL_df[target_vars].isna()]\n",
    "\n",
    "print(nan_rows.head())\n",
    "\n",
    "CRRL_subset = CRRL_df.dropna(subset=target_vars)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "CRRL_subset",
   "id": "7322cb594b22b832",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "CRRL_subset_only_targets = CRRL_subset[target_vars]\n",
    "CRRL_subset_only_targets"
   ],
   "id": "56100f6c8aa0e72e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(CRRL_subset_only_targets[target_vars].isna().sum())",
   "id": "f9a2c904b0dfaecf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"CRRL subsetted data:\")\n",
    "print(\"\\nStart: \", CRRL_subset['UTCTimestampCollected'].iloc[1])\n",
    "print(\"\\nEnd: \", CRRL_subset['UTCTimestampCollected'].iloc[-1])\n",
    "# check to make sure no nans\n",
    "CRRL_subset[target_vars].isna().sum()"
   ],
   "id": "6d7d3abda242d597",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T02:10:30.888854Z",
     "start_time": "2025-06-02T02:10:29.955878Z"
    }
   },
   "cell_type": "code",
   "source": [
    "RFSM_file = '../RFSM.csv'\n",
    "\n",
    "RFSM_df = pd.read_csv(RFSM_file)\n",
    "\n",
    "print(RFSM_df.head())\n",
    "\n",
    "target_vars = ['TAIR','VT90','SM02','PRES']\n",
    "target_vars_subset = ['TAIR','VT90','PRES']\n",
    "\n",
    "RFSM_subset = RFSM_df.dropna(subset=target_vars)\n",
    "RFSM_subset_2 = RFSM_df.dropna(subset=target_vars_subset)\n",
    "\n",
    "print(RFSM_df[target_vars].isna().sum())\n"
   ],
   "id": "85ba9c6983b2291f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/x3/czpqf5ks36d7yf5gcqbkp2140000gn/T/ipykernel_12952/440251310.py:3: DtypeWarning: Columns (3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  RFSM_df = pd.read_csv(RFSM_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  NetSiteAbbrev          County UTCTimestampCollected                  TAIR  \\\n",
      "0    Station ID  Station County             Timestamp  Air Temperature (°C)   \n",
      "1          RFSM       Breathitt   2019-12-10 08:25:00               12.5592   \n",
      "2          RFSM       Breathitt   2019-12-10 08:30:00               12.4164   \n",
      "3          RFSM       Breathitt   2019-12-10 08:35:00               12.3232   \n",
      "4          RFSM       Breathitt   2019-12-10 08:40:00               12.2973   \n",
      "\n",
      "            DWPT                PRCP           PRES                   RELH  \\\n",
      "0  Dewpoint (°C)  Precipitation (mm)  Pressure (mb)  Relative Humidity (%)   \n",
      "1        11.6742                 0.0        962.048                   94.3   \n",
      "2        11.8031                 0.0        962.208                   96.0   \n",
      "3        11.7733                 0.0        962.406                   96.4   \n",
      "4        11.8885                 0.0        962.527                   97.3   \n",
      "\n",
      "                     SRAD                      WDIR  ...  \\\n",
      "0  Solar Radiation (W/m²)  Wind Direction (degrees)  ...   \n",
      "1                0.165165                     228.3  ...   \n",
      "2                     0.0                     234.5  ...   \n",
      "3                0.165164                     240.9  ...   \n",
      "4                0.165165                     240.4  ...   \n",
      "\n",
      "                         SM02                        SM04  \\\n",
      "0  Soil Moisture at 2 in. (%)  Soil Moisture at 4 in. (%)   \n",
      "1                         NaN                         NaN   \n",
      "2                         NaN                         NaN   \n",
      "3                         NaN                         NaN   \n",
      "4                         NaN                         NaN   \n",
      "\n",
      "                             ST02                            ST04  \\\n",
      "0  Soil Temperature at 2 in. (°C)  Soil Temperature at 4 in. (°C)   \n",
      "1                             NaN                             NaN   \n",
      "2                             NaN                             NaN   \n",
      "3                             NaN                             NaN   \n",
      "4                             NaN                             NaN   \n",
      "\n",
      "                                 VT05                                VT20  \\\n",
      "0  Air Temperature at 0.5 meters (°C)  Air Temperature at 2.0 meters (°C)   \n",
      "1                                 NaN                                 NaN   \n",
      "2                                 NaN                                 NaN   \n",
      "3                                 NaN                                 NaN   \n",
      "4                                 NaN                                 NaN   \n",
      "\n",
      "                                 VT90                                 VR05  \\\n",
      "0  Air Temperature at 9.0 meters (°C)  Relative Humidity at 0.5 meters (%)   \n",
      "1                                 NaN                                  NaN   \n",
      "2                                 NaN                                  NaN   \n",
      "3                                 NaN                                  NaN   \n",
      "4                                 NaN                                  NaN   \n",
      "\n",
      "                                  VR20                                 VR90  \n",
      "0  Relative Humidity at 2.0 meters (%)  Relative Humidity At 9.0 meters (%)  \n",
      "1                                  NaN                                  NaN  \n",
      "2                                  NaN                                  NaN  \n",
      "3                                  NaN                                  NaN  \n",
      "4                                  NaN                                  NaN  \n",
      "\n",
      "[5 rows x 23 columns]\n",
      "TAIR       245\n",
      "VT90      6298\n",
      "SM02    570057\n",
      "PRES        10\n",
      "dtype: int64\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# this subset of all vars is empty\n",
    "RFSM_subset.head()"
   ],
   "id": "1fbfc53f193a3c38",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# second subset trying for more data, dropped the SM02 var as it has too many missing vals\n",
    "RFSM_subset_2.head()"
   ],
   "id": "3d551753130fce7b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# without SM02, with SM02 the dataset is empty\n",
    "print(\"RFSM subsetted data:\")\n",
    "print(\"Start: \", RFSM_subset_2['UTCTimestampCollected'].iloc[1])\n",
    "print(\"End: \", RFSM_subset_2['UTCTimestampCollected'].iloc[-1])\n",
    "print(RFSM_subset[target_vars_subset].isna().sum())"
   ],
   "id": "eb522a7dc18adb3e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "RFSM_subset_2.to_csv('./RFSM_subset_NO_SM02.csv')\n",
    "RFSM_subset.to_csv('./RFSM_subset.csv')\n"
   ],
   "id": "f144ec0b632a749f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "CRRL_subset.to_csv('./CRRL_subset.csv')",
   "id": "87219c8a32e362c5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# replacing missing values with NaN\n",
    "import pandas as pd\n",
    "\n",
    "# First, let's examine what non-numeric values exist in these columns\n",
    "print(\"Checking for non-numeric values in target columns:\")\n",
    "for col in target_vars:\n",
    "    if col in CRRL_df.columns:\n",
    "        # Convert to string to check for non-numeric values\n",
    "        non_numeric = CRRL_df[col].astype(str)\n",
    "        unique_values = non_numeric.unique()\n",
    "        print(f\"\\nColumn '{col}' unique string values (first 20):\")\n",
    "        print(unique_values[:20])\n",
    "\n",
    "# Create a list to track missing values before conversion\n",
    "missing_value_records = []\n",
    "\n",
    "# Convert columns to numeric and track what gets converted to NaN\n",
    "for col in target_vars:\n",
    "    if col in CRRL_df.columns:\n",
    "        # Store original values before conversion\n",
    "        original_values = CRRL_df[col].copy()\n",
    "\n",
    "        # Convert to numeric (non-numeric values become NaN)\n",
    "        CRRL_df[col] = pd.to_numeric(CRRL_df[col], errors='coerce')\n",
    "\n",
    "        # Find rows where conversion resulted in NaN (but weren't originally NaN)\n",
    "        # This identifies non-numeric values that were converted\n",
    "        was_non_numeric = pd.isna(CRRL_df[col]) & pd.notna(original_values)\n",
    "\n",
    "        # Also find rows that were already NaN\n",
    "        was_already_nan = pd.isna(original_values)\n",
    "\n",
    "        # Combine both cases\n",
    "        all_missing = pd.isna(CRRL_df[col])\n",
    "\n",
    "        # Record missing values with their datetime and original value\n",
    "        missing_indices = CRRL_df.index[all_missing]\n",
    "\n",
    "        for idx in missing_indices:\n",
    "            # Get datetime\n",
    "            datetime_col = 'UTCTimestampCollected'\n",
    "            if datetime_col in CRRL_df.columns:\n",
    "                timestamp = CRRL_df.loc[idx, datetime_col]\n",
    "            else:\n",
    "                timestamp = f\"Row_{idx}\"  # Fallback if no datetime column\n",
    "\n",
    "            original_val = original_values.iloc[idx] if idx < len(original_values) else 'Unknown'\n",
    "\n",
    "            missing_value_records.append({\n",
    "                'DateTime': timestamp,\n",
    "                'Column': col,\n",
    "                'Row_Index': idx,\n",
    "                'Original_Value': original_val,\n",
    "                'Missing_Type': 'Non-numeric_converted' if idx in CRRL_df.index[was_non_numeric] else 'Already_missing'\n",
    "            })\n",
    "\n",
    "# Create DataFrame to track missing values\n",
    "missing_values_df = pd.DataFrame(missing_value_records)\n",
    "\n",
    "# Save missing values tracking to CSV\n",
    "missing_values_df.to_csv('missing_values_log.csv', index=False)\n",
    "print(f\"\\nMissing values log saved to 'missing_values_log.csv'\")\n",
    "print(f\"Total missing values tracked: {len(missing_values_df)}\")\n",
    "\n",
    "# Display summary of missing values by column\n",
    "if len(missing_values_df) > 0:\n",
    "    print(\"\\nMissing values summary by column:\")\n",
    "    summary = missing_values_df.groupby('Column').size().reset_index(name='Count')\n",
    "    print(summary)\n",
    "\n",
    "    print(\"\\nSample of missing values log:\")\n",
    "    print(missing_values_df.head(10))\n",
    "\n",
    "# Now check for NaN rows in the cleaned data\n",
    "nan_rows = CRRL_df[CRRL_df[target_vars].isna().any(axis=1)]\n",
    "print(f\"\\nRows with NaN values after numeric conversion: {len(nan_rows)}\")\n",
    "\n",
    "# Create subset without NaN values\n",
    "CRRL_subset = CRRL_df.dropna(subset=target_vars)\n",
    "print(f\"\\nOriginal dataset size: {len(CRRL_df)}\")\n",
    "print(f\"Subset size after removing NaN: {len(CRRL_subset)}\")\n",
    "\n",
    "# Save the cleaned subset\n",
    "CRRL_subset.to_csv('CRRL_subset_cleaned.csv', index=False)\n",
    "print(\"Cleaned subset saved to 'CRRL_subset_cleaned.csv'\")"
   ],
   "id": "29a99701df153473",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T13:52:47.099296Z",
     "start_time": "2025-05-30T13:51:13.731267Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "CRRL_file = '../CRRL.csv'\n",
    "CRRL_df = pd.read_csv(CRRL_file)\n",
    "\n",
    "target_vars = ['TAIR','VT90','SM02','PRES']\n",
    "\n",
    "# First, let's examine what non-numeric values exist in these columns\n",
    "print(\"Checking for non-numeric values in target columns:\")\n",
    "for col in target_vars:\n",
    "    if col in CRRL_df.columns:\n",
    "        # Convert to string to check for non-numeric values\n",
    "        non_numeric = CRRL_df[col].astype(str)\n",
    "        unique_values = non_numeric.unique()\n",
    "        print(f\"\\nColumn '{col}' unique string values (first 20):\")\n",
    "        print(unique_values[:20])\n",
    "\n",
    "# Create a list to track missing values before conversion\n",
    "missing_value_records = []\n",
    "\n",
    "# Create a complete copy of the original dataframe for full cleaning\n",
    "CRRL_df_complete_cleaned = CRRL_df.copy()\n",
    "\n",
    "# Get all numeric columns (excluding datetime and other non-numeric columns you want to keep)\n",
    "# You can adjust this list based on your specific needs\n",
    "datetime_cols = ['UTCTimestampCollected']  # Add your datetime column names here\n",
    "text_cols = []  # Add any text columns you want to keep as-is\n",
    "\n",
    "# Identify columns that should be converted to numeric\n",
    "all_cols = CRRL_df.columns.tolist()\n",
    "numeric_cols = [col for col in all_cols if col not in datetime_cols + text_cols]\n",
    "\n",
    "print(f\"\\nColumns to be processed for numeric conversion: {len(numeric_cols)}\")\n",
    "print(f\"Columns to be kept as-is: {datetime_cols + text_cols}\")\n",
    "\n",
    "# Convert ALL numeric columns to numeric and track missing values for target vars\n",
    "for col in numeric_cols:\n",
    "    if col in CRRL_df.columns:\n",
    "        # Store original values before conversion\n",
    "        original_values = CRRL_df[col].copy()\n",
    "\n",
    "        # Convert to numeric (non-numeric values become NaN)\n",
    "        CRRL_df[col] = pd.to_numeric(CRRL_df[col], errors='coerce')\n",
    "        CRRL_df_complete_cleaned[col] = pd.to_numeric(CRRL_df_complete_cleaned[col], errors='coerce')\n",
    "\n",
    "        # Only track missing values for target variables (to avoid overwhelming log)\n",
    "        if col in target_vars:\n",
    "            # Find rows where conversion resulted in NaN (but weren't originally NaN)\n",
    "            was_non_numeric = pd.isna(CRRL_df[col]) & pd.notna(original_values)\n",
    "\n",
    "            # Also find rows that were already NaN\n",
    "            was_already_nan = pd.isna(original_values)\n",
    "\n",
    "            # Combine both cases\n",
    "            all_missing = pd.isna(CRRL_df[col])\n",
    "\n",
    "            # Record missing values with their datetime and original value\n",
    "            missing_indices = CRRL_df.index[all_missing]\n",
    "\n",
    "            for idx in missing_indices:\n",
    "                # Get datetime - adjust column name as needed\n",
    "                datetime_col = 'UTCTimestampCollected'  # Change this to your actual datetime column\n",
    "                if datetime_col in CRRL_df.columns:\n",
    "                    timestamp = CRRL_df.loc[idx, datetime_col]\n",
    "                else:\n",
    "                    timestamp = f\"Row_{idx}\"  # Fallback if no datetime column\n",
    "\n",
    "                original_val = original_values.iloc[idx] if idx < len(original_values) else 'Unknown'\n",
    "\n",
    "                missing_value_records.append({\n",
    "                    'DateTime': timestamp,\n",
    "                    'Column': col,\n",
    "                    'Row_Index': idx,\n",
    "                    'Original_Value': original_val,\n",
    "                    'Missing_Type': 'Non-numeric_converted' if idx in CRRL_df.index[was_non_numeric] else 'Already_missing'\n",
    "                })\n",
    "\n",
    "# Create DataFrame to track missing values\n",
    "missing_values_df = pd.DataFrame(missing_value_records)\n",
    "\n",
    "# Save missing values tracking to CSV\n",
    "missing_values_df.to_csv('missing_values_log.csv', index=False)\n",
    "print(f\"\\nMissing values log saved to 'missing_values_log.csv'\")\n",
    "print(f\"Total missing values tracked: {len(missing_values_df)}\")\n",
    "\n",
    "# Display summary of missing values by column\n",
    "if len(missing_values_df) > 0:\n",
    "    print(\"\\nMissing values summary by column:\")\n",
    "    summary = missing_values_df.groupby('Column').size().reset_index(name='Count')\n",
    "    print(summary)\n",
    "\n",
    "    print(\"\\nSample of missing values log:\")\n",
    "    print(missing_values_df.head(10))\n",
    "\n",
    "# Now check for NaN rows in the cleaned data\n",
    "nan_rows = CRRL_df[CRRL_df[target_vars].isna().any(axis=1)]\n",
    "print(f\"\\nRows with NaN values in target columns after numeric conversion: {len(nan_rows)}\")\n",
    "\n",
    "# Create subset without NaN values (target variables only)\n",
    "CRRL_subset = CRRL_df.dropna(subset=target_vars)\n",
    "print(f\"\\nOriginal dataset size: {len(CRRL_df)}\")\n",
    "print(f\"Target variables subset size after removing NaN: {len(CRRL_subset)}\")\n",
    "\n",
    "# Check missing values in the complete cleaned dataframe\n",
    "print(f\"\\nComplete cleaned dataframe missing values summary:\")\n",
    "complete_missing_summary = CRRL_df_complete_cleaned.isna().sum()\n",
    "complete_missing_summary = complete_missing_summary[complete_missing_summary > 0].sort_values(ascending=False)\n",
    "print(complete_missing_summary)\n",
    "\n",
    "# Save all the dataframes\n",
    "CRRL_subset.to_csv('CRRL_subset_cleaned.csv', index=False)\n",
    "print(\"Target variables subset saved to 'CRRL_subset_cleaned.csv'\")\n",
    "\n",
    "CRRL_df_complete_cleaned.to_csv('CRRL_complete_cleaned.csv', index=False)\n",
    "print(\"Complete cleaned dataframe saved to 'CRRL_complete_cleaned.csv'\")\n",
    "\n",
    "# Also save the original dataframe with missing values converted to NaN (but no rows removed)\n",
    "CRRL_df.to_csv('CRRL_with_NaN_converted.csv', index=False)\n",
    "print(\"Original dataframe with NaN conversions saved to 'CRRL_with_NaN_converted.csv'\")\n",
    "\n",
    "print(f\"\\nSummary:\")\n",
    "print(f\"- Original dataset: {len(CRRL_df)} rows\")\n",
    "print(f\"- Target subset (no NaN in target vars): {len(CRRL_subset)} rows\")\n",
    "print(f\"- Complete cleaned dataset: {len(CRRL_df_complete_cleaned)} rows (same as original, just cleaned)\")"
   ],
   "id": "999cb519e966464b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/x3/czpqf5ks36d7yf5gcqbkp2140000gn/T/ipykernel_7344/1156744443.py:5: DtypeWarning: Columns (3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  CRRL_df = pd.read_csv(CRRL_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for non-numeric values in target columns:\n",
      "\n",
      "Column 'TAIR' unique string values (first 20):\n",
      "['Air Temperature (°C)' '20.4219' '20.2758' '20.2288' '19.1393' '18.1505'\n",
      " '17.4197' '16.8907' '16.3261' '16.313' '15.8912' '14.7009' '14.5218'\n",
      " '13.8902' '13.5987' '13.1205' '13.1114' '13.0171' '12.6939' '12.5963']\n",
      "\n",
      "Column 'VT90' unique string values (first 20):\n",
      "['Air Temperature at 9.0 meters (°C)' 'nan' '18.92' '18.81' '19.16'\n",
      " '18.93' '18.85' '19.2' '19.44' '19.63' '19.66' '20.07' '19.88' '19.9'\n",
      " '19.95' '20.19' '20.43' '20.32' '20.24' '20.4']\n",
      "\n",
      "Column 'SM02' unique string values (first 20):\n",
      "['Soil Moisture at 2 in. (%)' '0.316' 'nan' '0.315' '0.314' '0.317'\n",
      " '0.318' '0.312' '0.308' '0.307' '0.305' '0.303' '0.301' '0.297' '0.295'\n",
      " '0.296' '0.293' '0.294' '0.299' '0.298']\n",
      "\n",
      "Column 'PRES' unique string values (first 20):\n",
      "['Pressure (mb)' 'nan' '469.875' '998.881' '998.859' '998.88' '998.94'\n",
      " '998.894' '998.81' '998.756' '998.642' '998.588' '998.502' '998.356'\n",
      " '998.332' '998.344' '998.325' '998.286' '998.232' '998.245']\n",
      "\n",
      "Columns to be processed for numeric conversion: 22\n",
      "Columns to be kept as-is: ['UTCTimestampCollected']\n",
      "\n",
      "Missing values log saved to 'missing_values_log.csv'\n",
      "Total missing values tracked: 796463\n",
      "\n",
      "Missing values summary by column:\n",
      "  Column   Count\n",
      "0   PRES   23019\n",
      "1   SM02  664494\n",
      "2   TAIR     374\n",
      "3   VT90  108576\n",
      "\n",
      "Sample of missing values log:\n",
      "              DateTime Column  Row_Index        Original_Value  \\\n",
      "0            Timestamp   TAIR          0  Air Temperature (°C)   \n",
      "1  2018-06-30 13:45:00   TAIR      17446                   NaN   \n",
      "2  2018-06-30 13:50:00   TAIR      17447                   NaN   \n",
      "3  2018-07-18 20:25:00   TAIR      22710                   NaN   \n",
      "4  2018-07-18 20:30:00   TAIR      22711                   NaN   \n",
      "5  2018-07-18 20:35:00   TAIR      22712                   NaN   \n",
      "6  2018-07-18 20:40:00   TAIR      22713                   NaN   \n",
      "7  2018-07-18 20:45:00   TAIR      22714                   NaN   \n",
      "8  2018-07-18 20:50:00   TAIR      22715                   NaN   \n",
      "9  2018-07-18 20:55:00   TAIR      22716                   NaN   \n",
      "\n",
      "            Missing_Type  \n",
      "0  Non-numeric_converted  \n",
      "1        Already_missing  \n",
      "2        Already_missing  \n",
      "3        Already_missing  \n",
      "4        Already_missing  \n",
      "5        Already_missing  \n",
      "6        Already_missing  \n",
      "7        Already_missing  \n",
      "8        Already_missing  \n",
      "9        Already_missing  \n",
      "\n",
      "Rows with NaN values in target columns after numeric conversion: 671175\n",
      "\n",
      "Original dataset size: 739447\n",
      "Target variables subset size after removing NaN: 68272\n",
      "\n",
      "Complete cleaned dataframe missing values summary:\n",
      "NetSiteAbbrev    739447\n",
      "County           739447\n",
      "ST02             665555\n",
      "ST04             665553\n",
      "SM02             664494\n",
      "SM04             664492\n",
      "VT90             108576\n",
      "VT05             108576\n",
      "VT20             108575\n",
      "VR20             108573\n",
      "VR05             108572\n",
      "VR90             108572\n",
      "PRES              23019\n",
      "PRCP               1793\n",
      "WDSD                487\n",
      "WSPD                487\n",
      "WDIR                487\n",
      "WSSD                487\n",
      "DWPT                376\n",
      "TAIR                374\n",
      "RELH                346\n",
      "SRAD                344\n",
      "dtype: int64\n",
      "Target variables subset saved to 'CRRL_subset_cleaned.csv'\n",
      "Complete cleaned dataframe saved to 'CRRL_complete_cleaned.csv'\n",
      "Original dataframe with NaN conversions saved to 'CRRL_with_NaN_converted.csv'\n",
      "\n",
      "Summary:\n",
      "- Original dataset: 739447 rows\n",
      "- Target subset (no NaN in target vars): 68272 rows\n",
      "- Complete cleaned dataset: 739447 rows (same as original, just cleaned)\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "c78f4f3251b5f522",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T13:54:27.745500Z",
     "start_time": "2025-05-30T13:54:22.613459Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the variables we're interested in\n",
    "key_variables = ['VT90', 'SM02', 'TAIR', 'PRES']\n",
    "datetime_col = 'UTCTimestampCollected'\n",
    "\n",
    "# Open a text file for writing\n",
    "with open('../unsorted data/data_gaps_analysis.txt', 'w') as f:\n",
    "\n",
    "    f.write(f\"Looking for all chunks where all variables have data: {key_variables}\\n\")\n",
    "    f.write(\"-\" * 60 + \"\\n\")\n",
    "\n",
    "    # Sort by datetime to ensure chronological order\n",
    "    df_sorted = CRRL_df_complete_cleaned\n",
    "\n",
    "    # Find rows where ALL variables are present (not NaN)\n",
    "    all_present = df_sorted[key_variables].notna().all(axis=1)\n",
    "\n",
    "    # Find chunks of continuous complete data\n",
    "    chunks = []\n",
    "    in_chunk = False\n",
    "    chunk_start = None\n",
    "\n",
    "    for i, has_all_data in enumerate(all_present):\n",
    "        if has_all_data and not in_chunk:\n",
    "            # Start of a new chunk\n",
    "            chunk_start = i\n",
    "            in_chunk = True\n",
    "        elif not has_all_data and in_chunk:\n",
    "            # End of current chunk\n",
    "            chunk_end = i - 1\n",
    "            chunks.append((chunk_start, chunk_end))\n",
    "            in_chunk = False\n",
    "\n",
    "    # Handle case where dataset ends with a complete chunk\n",
    "    if in_chunk:\n",
    "        chunks.append((chunk_start, len(df_sorted) - 1))\n",
    "\n",
    "    # Write chunk information to file\n",
    "    if chunks:\n",
    "        f.write(f\"Found {len(chunks)} chunks with complete data for all variables:\\n\\n\")\n",
    "\n",
    "        total_complete_rows = 0\n",
    "\n",
    "        for i, (start_idx, end_idx) in enumerate(chunks, 1):\n",
    "            start_date = df_sorted.iloc[start_idx][datetime_col]\n",
    "            end_date = df_sorted.iloc[end_idx][datetime_col]\n",
    "            chunk_duration = end_idx - start_idx + 1\n",
    "            total_complete_rows += chunk_duration\n",
    "\n",
    "            f.write(f\"Chunk {i}:\\n\")\n",
    "            f.write(f\"  Start: {start_date} (row {start_idx})\\n\")\n",
    "            f.write(f\"  End:   {end_date} (row {end_idx})\\n\")\n",
    "            f.write(f\"  Duration: {chunk_duration} rows\\n\")\n",
    "\n",
    "            # Calculate time duration\n",
    "            try:\n",
    "                time_duration = end_date - start_date\n",
    "                f.write(f\"  Time span: {time_duration}\\n\")\n",
    "            except:\n",
    "                pass\n",
    "            f.write(\"\\n\")\n",
    "\n",
    "        # Summary\n",
    "        total_rows = len(df_sorted)\n",
    "        complete_percentage = (total_complete_rows / total_rows) * 100\n",
    "\n",
    "        f.write(f\"Summary:\\n\")\n",
    "        f.write(f\"  Total rows in dataset: {total_rows}\\n\")\n",
    "        f.write(f\"  Rows with all variables present: {total_complete_rows} ({complete_percentage:.1f}%)\\n\")\n",
    "        f.write(f\"  Rows with missing data: {total_rows - total_complete_rows} ({100 - complete_percentage:.1f}%)\\n\")\n",
    "        f.write(f\"  Number of complete data chunks: {len(chunks)}\\n\")\n",
    "\n",
    "        if len(chunks) > 1:\n",
    "            f.write(f\"\\nGaps between chunks:\\n\")\n",
    "            for i in range(len(chunks) - 1):\n",
    "                gap_start = chunks[i][1] + 1  # End of current chunk + 1\n",
    "                gap_end = chunks[i+1][0] - 1  # Start of next chunk - 1\n",
    "                gap_start_date = df_sorted.iloc[gap_start][datetime_col]\n",
    "                gap_end_date = df_sorted.iloc[gap_end][datetime_col]\n",
    "                gap_duration = gap_end - gap_start + 1\n",
    "\n",
    "                f.write(f\"  Gap {i+1}: {gap_start_date} to {gap_end_date} ({gap_duration} rows)\\n\")\n",
    "\n",
    "    else:\n",
    "        f.write(\"❌ No chunks found where all variables have data simultaneously\\n\")\n",
    "\n",
    "        # Show individual variable availability\n",
    "        f.write(\"\\nIndividual variable availability:\\n\")\n",
    "        for var in key_variables:\n",
    "            has_data = df_sorted[var].notna().any()\n",
    "            if has_data:\n",
    "                first_date = df_sorted[df_sorted[var].notna()].iloc[0][datetime_col]\n",
    "                last_date = df_sorted[df_sorted[var].notna()].iloc[-1][datetime_col]\n",
    "                total_available = df_sorted[var].notna().sum()\n",
    "                f.write(f\"  {var}: {first_date} to {last_date} ({total_available} rows)\\n\")\n",
    "            else:\n",
    "                f.write(f\"  {var}: No data available\\n\")\n",
    "\n",
    "print(\"Gap analysis saved to 'data_gaps_analysis.txt'\")"
   ],
   "id": "bcded8c6a03be9b3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gap analysis saved to 'data_gaps_analysis.txt'\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T01:56:37.454942Z",
     "start_time": "2025-06-02T01:56:32.969946Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# load RFSM and CRRL data from google drive folder, Carroll & Breathitt County\n",
    "# subset the data based on TAIR, VT90, SM02, PRES\n",
    "# for the RFSM dataset, I have removed the SM02 feature as it is absent from the subset data\n",
    "import pandas as pd\n",
    "\n",
    "CRRL_file = '../CRRL.csv'\n",
    "\n",
    "CRRL_df = pd.read_csv(CRRL_file)\n",
    "\n",
    "target_vars = ['SM02', 'ST02', 'SM04', 'ST04']\n",
    "\n",
    "CRRL_subset_NO_SOIL = CRRL_df.drop(columns=target_vars)\n",
    "\n",
    "CRRL_subset_NO_SOIL.to_csv(\"CRRL_subset_NO_SOIL.csv\", index=False)"
   ],
   "id": "1a5d1486694b1e83",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/x3/czpqf5ks36d7yf5gcqbkp2140000gn/T/ipykernel_12952/3580229257.py:8: DtypeWarning: Columns (3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  CRRL_df = pd.read_csv(CRRL_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  NetSiteAbbrev          County UTCTimestampCollected                  TAIR  \\\n",
      "0    Station ID  Station County             Timestamp  Air Temperature (°C)   \n",
      "1          CRRL         Carroll   2018-05-01 00:00:00               20.4219   \n",
      "2          CRRL         Carroll   2018-05-01 00:05:00               20.2758   \n",
      "3          CRRL         Carroll   2018-05-01 00:10:00               20.2288   \n",
      "4          CRRL         Carroll   2018-05-01 00:15:00               19.1393   \n",
      "\n",
      "            DWPT                PRCP           PRES                   RELH  \\\n",
      "0  Dewpoint (°C)  Precipitation (mm)  Pressure (mb)  Relative Humidity (%)   \n",
      "1      -0.958412                 0.0            NaN                  23.79   \n",
      "2        -1.1164                 0.0            NaN                  23.73   \n",
      "3      -0.774945                 0.0            NaN                   24.4   \n",
      "4        1.91157                 0.0            NaN                  31.69   \n",
      "\n",
      "                     SRAD                      WDIR  ...  \\\n",
      "0  Solar Radiation (W/m²)  Wind Direction (degrees)  ...   \n",
      "1                 49.6919                     202.9  ...   \n",
      "2                 31.8631                     187.6  ...   \n",
      "3                 24.2694                     187.4  ...   \n",
      "4                 19.4822                     192.3  ...   \n",
      "\n",
      "                         SM02                        SM04  \\\n",
      "0  Soil Moisture at 2 in. (%)  Soil Moisture at 4 in. (%)   \n",
      "1                       0.316                       0.301   \n",
      "2                         NaN                         NaN   \n",
      "3                         NaN                         NaN   \n",
      "4                         NaN                         NaN   \n",
      "\n",
      "                             ST02                            ST04  \\\n",
      "0  Soil Temperature at 2 in. (°C)  Soil Temperature at 4 in. (°C)   \n",
      "1                            15.5                            15.4   \n",
      "2                             NaN                             NaN   \n",
      "3                             NaN                             NaN   \n",
      "4                             NaN                             NaN   \n",
      "\n",
      "                                 VT05                                VT20  \\\n",
      "0  Air Temperature at 0.5 meters (°C)  Air Temperature at 2.0 meters (°C)   \n",
      "1                                 NaN                                 NaN   \n",
      "2                                 NaN                                 NaN   \n",
      "3                                 NaN                                 NaN   \n",
      "4                                 NaN                                 NaN   \n",
      "\n",
      "                                 VT90                                 VR05  \\\n",
      "0  Air Temperature at 9.0 meters (°C)  Relative Humidity at 0.5 meters (%)   \n",
      "1                                 NaN                                  NaN   \n",
      "2                                 NaN                                  NaN   \n",
      "3                                 NaN                                  NaN   \n",
      "4                                 NaN                                  NaN   \n",
      "\n",
      "                                  VR20                                 VR90  \n",
      "0  Relative Humidity at 2.0 meters (%)  Relative Humidity At 9.0 meters (%)  \n",
      "1                                  NaN                                  NaN  \n",
      "2                                  NaN                                  NaN  \n",
      "3                                  NaN                                  NaN  \n",
      "4                                  NaN                                  NaN  \n",
      "\n",
      "[5 rows x 23 columns]\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T02:15:19.741192Z",
     "start_time": "2025-06-02T02:14:31.855717Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# replacing missing values with NaN\n",
    "import pandas as pd\n",
    "\n",
    "file = '/Users/cylis/Work/mes_summer25/RFSM_subset_NO_SM02.csv'\n",
    "\n",
    "RFSM_df = pd.read_csv(file)\n",
    "# First, let's examine what non-numeric values exist in these columns\n",
    "print(\"Checking for non-numeric values in target columns:\")\n",
    "for col in target_vars:\n",
    "    if col in RFSM_df.columns:\n",
    "        # Convert to string to check for non-numeric values\n",
    "        non_numeric = RFSM_df[col].astype(str)\n",
    "        unique_values = non_numeric.unique()\n",
    "        print(f\"\\nColumn '{col}' unique string values (first 20):\")\n",
    "        print(unique_values[:20])\n",
    "\n",
    "# Create a list to track missing values before conversion\n",
    "missing_value_records = []\n",
    "\n",
    "# Convert columns to numeric and track what gets converted to NaN\n",
    "for col in target_vars:\n",
    "    if col in RFSM_df.columns:\n",
    "        # Store original values before conversion\n",
    "        original_values = RFSM_df[col].copy()\n",
    "\n",
    "        # Convert to numeric (non-numeric values become NaN)\n",
    "        RFSM_df[col] = pd.to_numeric(RFSM_df[col], errors='coerce')\n",
    "\n",
    "        # Find rows where conversion resulted in NaN (but weren't originally NaN)\n",
    "        was_non_numeric = pd.isna(RFSM_df[col]) & pd.notna(original_values)\n",
    "\n",
    "        # Also find rows that were already NaN\n",
    "        was_already_nan = pd.isna(original_values)\n",
    "\n",
    "        # Combine both cases\n",
    "        all_missing = pd.isna(RFSM_df[col])\n",
    "\n",
    "        # Record missing values with their datetime and original value\n",
    "        missing_indices = RFSM_df.index[all_missing]\n",
    "\n",
    "        for idx in missing_indices:\n",
    "            # Get datetime\n",
    "            datetime_col = 'UTCTimestampCollected'\n",
    "            if datetime_col in RFSM_df.columns:\n",
    "                timestamp = RFSM_df.loc[idx, datetime_col]\n",
    "            else:\n",
    "                timestamp = f\"Row_{idx}\"  # Fallback if no datetime column\n",
    "\n",
    "            original_val = original_values.iloc[idx] if idx < len(original_values) else 'Unknown'\n",
    "\n",
    "            missing_value_records.append({\n",
    "                'DateTime': timestamp,\n",
    "                'Column': col,\n",
    "                'Row_Index': idx,\n",
    "                'Original_Value': original_val,\n",
    "                'Missing_Type': 'Non-numeric_converted' if idx in RFSM_df.index[was_non_numeric] else 'Already_missing'\n",
    "            })\n",
    "\n",
    "# Create DataFrame to track missing values\n",
    "missing_values_df = pd.DataFrame(missing_value_records)\n",
    "\n",
    "# Save missing values tracking to CSV\n",
    "missing_values_df.to_csv('RFSM_missing_values_log.csv', index=False)\n",
    "print(f\"\\nMissing values log saved to 'RFSM_missing_values_log.csv'\")\n",
    "print(f\"Total missing values tracked: {len(missing_values_df)}\")\n",
    "\n",
    "# Display summary of missing values by column\n",
    "if len(missing_values_df) > 0:\n",
    "    print(\"\\nMissing values summary by column:\")\n",
    "    summary = missing_values_df.groupby('Column').size().reset_index(name='Count')\n",
    "    print(summary)\n",
    "\n",
    "    print(\"\\nSample of missing values log:\")\n",
    "    print(missing_values_df.head(10))\n",
    "\n",
    "# Now check for NaN rows in the cleaned data\n",
    "nan_rows = RFSM_df[RFSM_df[target_vars].isna().any(axis=1)]\n",
    "print(f\"\\nRows with NaN values after numeric conversion: {len(nan_rows)}\")\n",
    "\n",
    "# Create subset without NaN values\n",
    "RFSM_subset = RFSM_df.dropna(subset=target_vars)\n",
    "print(f\"\\nOriginal dataset size: {len(RFSM_df)}\")\n",
    "print(f\"Subset size after removing NaN: {len(RFSM_subset)}\")\n",
    "\n",
    "# Save the cleaned subset\n",
    "RFSM_subset.to_csv('RFSM_subset_cleaned.csv', index=False)\n",
    "print(\"Cleaned subset saved to 'RFSM_subset_cleaned.csv'\")"
   ],
   "id": "14e05079ecf8f818",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/x3/czpqf5ks36d7yf5gcqbkp2140000gn/T/ipykernel_12952/442229842.py:6: DtypeWarning: Columns (4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  RFSM_df = pd.read_csv(file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for non-numeric values in target columns:\n",
      "\n",
      "Column 'TAIR' unique string values (first 20):\n",
      "['Air Temperature (°C)' '4.04204' '4.08667' '4.07621' '4.11729' '4.09035'\n",
      " '4.07849' '4.06616' '4.05743' '4.01165' '3.99285' '3.96894' '3.94577'\n",
      " '3.95389' '3.95062' '3.91289' '3.97761' '3.93206' '3.95066' '3.96472']\n",
      "\n",
      "Column 'VT90' unique string values (first 20):\n",
      "['Air Temperature at 9.0 meters (°C)' '4.272' '4.273' '4.298' '4.283'\n",
      " '4.275' '4.271' '4.238' '4.221' '4.224' '4.184' '4.141' '4.144' '4.145'\n",
      " '4.142' '4.139' '4.138' '4.135' '4.087' '4.073']\n",
      "\n",
      "Column 'SM02' unique string values (first 20):\n",
      "['Soil Moisture at 2 in. (%)' 'nan']\n",
      "\n",
      "Column 'PRES' unique string values (first 20):\n",
      "['Pressure (mb)' '964.091' '964.207' '964.287' '964.243' '964.363'\n",
      " '964.406' '964.559' '964.523' '964.603' '964.521' '964.56' '964.602'\n",
      " '964.562' '964.604' '964.442' '964.403' '964.44' '964.367' '964.289']\n",
      "\n",
      "Missing values log saved to 'RFSM_missing_values_log.csv'\n",
      "Total missing values tracked: 563579\n",
      "\n",
      "Missing values summary by column:\n",
      "  Column   Count\n",
      "0   PRES       1\n",
      "1   SM02  563576\n",
      "2   TAIR       1\n",
      "3   VT90       1\n",
      "\n",
      "Sample of missing values log:\n",
      "              DateTime Column  Row_Index                      Original_Value  \\\n",
      "0            Timestamp   TAIR          0                Air Temperature (°C)   \n",
      "1            Timestamp   VT90          0  Air Temperature at 9.0 meters (°C)   \n",
      "2            Timestamp   SM02          0          Soil Moisture at 2 in. (%)   \n",
      "3  2020-01-01 00:00:00   SM02          1                                 NaN   \n",
      "4  2020-01-01 00:05:00   SM02          2                                 NaN   \n",
      "5  2020-01-01 00:10:00   SM02          3                                 NaN   \n",
      "6  2020-01-01 00:15:00   SM02          4                                 NaN   \n",
      "7  2020-01-01 00:20:00   SM02          5                                 NaN   \n",
      "8  2020-01-01 00:25:00   SM02          6                                 NaN   \n",
      "9  2020-01-01 00:30:00   SM02          7                                 NaN   \n",
      "\n",
      "            Missing_Type  \n",
      "0  Non-numeric_converted  \n",
      "1  Non-numeric_converted  \n",
      "2  Non-numeric_converted  \n",
      "3        Already_missing  \n",
      "4        Already_missing  \n",
      "5        Already_missing  \n",
      "6        Already_missing  \n",
      "7        Already_missing  \n",
      "8        Already_missing  \n",
      "9        Already_missing  \n",
      "\n",
      "Rows with NaN values after numeric conversion: 563576\n",
      "\n",
      "Original dataset size: 563576\n",
      "Subset size after removing NaN: 0\n",
      "Cleaned subset saved to 'RFSM_subset_cleaned.csv'\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T21:53:28.868969Z",
     "start_time": "2025-06-06T21:53:28.118116Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "file = ('/Users/cylis/Work/mes_summer25/original/RFSM.csv')\n",
    "\n",
    "df = pd.read_csv(file)\n",
    "df.head()"
   ],
   "id": "78573a14be250c56",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/x3/czpqf5ks36d7yf5gcqbkp2140000gn/T/ipykernel_12952/975556766.py:5: DtypeWarning: Columns (3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  NetSiteAbbrev          County UTCTimestampCollected                  TAIR  \\\n",
       "0    Station ID  Station County             Timestamp  Air Temperature (°C)   \n",
       "1          RFSM       Breathitt   2019-12-10 08:25:00               12.5592   \n",
       "2          RFSM       Breathitt   2019-12-10 08:30:00               12.4164   \n",
       "3          RFSM       Breathitt   2019-12-10 08:35:00               12.3232   \n",
       "4          RFSM       Breathitt   2019-12-10 08:40:00               12.2973   \n",
       "\n",
       "            DWPT                PRCP           PRES                   RELH  \\\n",
       "0  Dewpoint (°C)  Precipitation (mm)  Pressure (mb)  Relative Humidity (%)   \n",
       "1        11.6742                 0.0        962.048                   94.3   \n",
       "2        11.8031                 0.0        962.208                   96.0   \n",
       "3        11.7733                 0.0        962.406                   96.4   \n",
       "4        11.8885                 0.0        962.527                   97.3   \n",
       "\n",
       "                     SRAD                      WDIR  ...  \\\n",
       "0  Solar Radiation (W/m²)  Wind Direction (degrees)  ...   \n",
       "1                0.165165                     228.3  ...   \n",
       "2                     0.0                     234.5  ...   \n",
       "3                0.165164                     240.9  ...   \n",
       "4                0.165165                     240.4  ...   \n",
       "\n",
       "                         SM02                        SM04  \\\n",
       "0  Soil Moisture at 2 in. (%)  Soil Moisture at 4 in. (%)   \n",
       "1                         NaN                         NaN   \n",
       "2                         NaN                         NaN   \n",
       "3                         NaN                         NaN   \n",
       "4                         NaN                         NaN   \n",
       "\n",
       "                             ST02                            ST04  \\\n",
       "0  Soil Temperature at 2 in. (°C)  Soil Temperature at 4 in. (°C)   \n",
       "1                             NaN                             NaN   \n",
       "2                             NaN                             NaN   \n",
       "3                             NaN                             NaN   \n",
       "4                             NaN                             NaN   \n",
       "\n",
       "                                 VT05                                VT20  \\\n",
       "0  Air Temperature at 0.5 meters (°C)  Air Temperature at 2.0 meters (°C)   \n",
       "1                                 NaN                                 NaN   \n",
       "2                                 NaN                                 NaN   \n",
       "3                                 NaN                                 NaN   \n",
       "4                                 NaN                                 NaN   \n",
       "\n",
       "                                 VT90                                 VR05  \\\n",
       "0  Air Temperature at 9.0 meters (°C)  Relative Humidity at 0.5 meters (%)   \n",
       "1                                 NaN                                  NaN   \n",
       "2                                 NaN                                  NaN   \n",
       "3                                 NaN                                  NaN   \n",
       "4                                 NaN                                  NaN   \n",
       "\n",
       "                                  VR20                                 VR90  \n",
       "0  Relative Humidity at 2.0 meters (%)  Relative Humidity At 9.0 meters (%)  \n",
       "1                                  NaN                                  NaN  \n",
       "2                                  NaN                                  NaN  \n",
       "3                                  NaN                                  NaN  \n",
       "4                                  NaN                                  NaN  \n",
       "\n",
       "[5 rows x 23 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NetSiteAbbrev</th>\n",
       "      <th>County</th>\n",
       "      <th>UTCTimestampCollected</th>\n",
       "      <th>TAIR</th>\n",
       "      <th>DWPT</th>\n",
       "      <th>PRCP</th>\n",
       "      <th>PRES</th>\n",
       "      <th>RELH</th>\n",
       "      <th>SRAD</th>\n",
       "      <th>WDIR</th>\n",
       "      <th>...</th>\n",
       "      <th>SM02</th>\n",
       "      <th>SM04</th>\n",
       "      <th>ST02</th>\n",
       "      <th>ST04</th>\n",
       "      <th>VT05</th>\n",
       "      <th>VT20</th>\n",
       "      <th>VT90</th>\n",
       "      <th>VR05</th>\n",
       "      <th>VR20</th>\n",
       "      <th>VR90</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Station ID</td>\n",
       "      <td>Station County</td>\n",
       "      <td>Timestamp</td>\n",
       "      <td>Air Temperature (°C)</td>\n",
       "      <td>Dewpoint (°C)</td>\n",
       "      <td>Precipitation (mm)</td>\n",
       "      <td>Pressure (mb)</td>\n",
       "      <td>Relative Humidity (%)</td>\n",
       "      <td>Solar Radiation (W/m²)</td>\n",
       "      <td>Wind Direction (degrees)</td>\n",
       "      <td>...</td>\n",
       "      <td>Soil Moisture at 2 in. (%)</td>\n",
       "      <td>Soil Moisture at 4 in. (%)</td>\n",
       "      <td>Soil Temperature at 2 in. (°C)</td>\n",
       "      <td>Soil Temperature at 4 in. (°C)</td>\n",
       "      <td>Air Temperature at 0.5 meters (°C)</td>\n",
       "      <td>Air Temperature at 2.0 meters (°C)</td>\n",
       "      <td>Air Temperature at 9.0 meters (°C)</td>\n",
       "      <td>Relative Humidity at 0.5 meters (%)</td>\n",
       "      <td>Relative Humidity at 2.0 meters (%)</td>\n",
       "      <td>Relative Humidity At 9.0 meters (%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RFSM</td>\n",
       "      <td>Breathitt</td>\n",
       "      <td>2019-12-10 08:25:00</td>\n",
       "      <td>12.5592</td>\n",
       "      <td>11.6742</td>\n",
       "      <td>0.0</td>\n",
       "      <td>962.048</td>\n",
       "      <td>94.3</td>\n",
       "      <td>0.165165</td>\n",
       "      <td>228.3</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RFSM</td>\n",
       "      <td>Breathitt</td>\n",
       "      <td>2019-12-10 08:30:00</td>\n",
       "      <td>12.4164</td>\n",
       "      <td>11.8031</td>\n",
       "      <td>0.0</td>\n",
       "      <td>962.208</td>\n",
       "      <td>96.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>234.5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RFSM</td>\n",
       "      <td>Breathitt</td>\n",
       "      <td>2019-12-10 08:35:00</td>\n",
       "      <td>12.3232</td>\n",
       "      <td>11.7733</td>\n",
       "      <td>0.0</td>\n",
       "      <td>962.406</td>\n",
       "      <td>96.4</td>\n",
       "      <td>0.165164</td>\n",
       "      <td>240.9</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RFSM</td>\n",
       "      <td>Breathitt</td>\n",
       "      <td>2019-12-10 08:40:00</td>\n",
       "      <td>12.2973</td>\n",
       "      <td>11.8885</td>\n",
       "      <td>0.0</td>\n",
       "      <td>962.527</td>\n",
       "      <td>97.3</td>\n",
       "      <td>0.165165</td>\n",
       "      <td>240.4</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T21:53:40.193607Z",
     "start_time": "2025-06-06T21:53:40.108629Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = df.drop(0)\n",
    "df.head()"
   ],
   "id": "79a12cd9c7588f06",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  NetSiteAbbrev     County UTCTimestampCollected     TAIR     DWPT PRCP  \\\n",
       "1          RFSM  Breathitt   2019-12-10 08:25:00  12.5592  11.6742  0.0   \n",
       "2          RFSM  Breathitt   2019-12-10 08:30:00  12.4164  11.8031  0.0   \n",
       "3          RFSM  Breathitt   2019-12-10 08:35:00  12.3232  11.7733  0.0   \n",
       "4          RFSM  Breathitt   2019-12-10 08:40:00  12.2973  11.8885  0.0   \n",
       "5          RFSM  Breathitt   2019-12-10 08:45:00  12.3016  11.9395  0.0   \n",
       "\n",
       "      PRES  RELH      SRAD   WDIR  ... SM02 SM04 ST02 ST04 VT05 VT20 VT90  \\\n",
       "1  962.048  94.3  0.165165  228.3  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "2  962.208  96.0       0.0  234.5  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "3  962.406  96.4  0.165164  240.9  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "4  962.527  97.3  0.165165  240.4  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "5  962.568  97.6  0.165166  230.0  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "\n",
       "  VR05 VR20 VR90  \n",
       "1  NaN  NaN  NaN  \n",
       "2  NaN  NaN  NaN  \n",
       "3  NaN  NaN  NaN  \n",
       "4  NaN  NaN  NaN  \n",
       "5  NaN  NaN  NaN  \n",
       "\n",
       "[5 rows x 23 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NetSiteAbbrev</th>\n",
       "      <th>County</th>\n",
       "      <th>UTCTimestampCollected</th>\n",
       "      <th>TAIR</th>\n",
       "      <th>DWPT</th>\n",
       "      <th>PRCP</th>\n",
       "      <th>PRES</th>\n",
       "      <th>RELH</th>\n",
       "      <th>SRAD</th>\n",
       "      <th>WDIR</th>\n",
       "      <th>...</th>\n",
       "      <th>SM02</th>\n",
       "      <th>SM04</th>\n",
       "      <th>ST02</th>\n",
       "      <th>ST04</th>\n",
       "      <th>VT05</th>\n",
       "      <th>VT20</th>\n",
       "      <th>VT90</th>\n",
       "      <th>VR05</th>\n",
       "      <th>VR20</th>\n",
       "      <th>VR90</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RFSM</td>\n",
       "      <td>Breathitt</td>\n",
       "      <td>2019-12-10 08:25:00</td>\n",
       "      <td>12.5592</td>\n",
       "      <td>11.6742</td>\n",
       "      <td>0.0</td>\n",
       "      <td>962.048</td>\n",
       "      <td>94.3</td>\n",
       "      <td>0.165165</td>\n",
       "      <td>228.3</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RFSM</td>\n",
       "      <td>Breathitt</td>\n",
       "      <td>2019-12-10 08:30:00</td>\n",
       "      <td>12.4164</td>\n",
       "      <td>11.8031</td>\n",
       "      <td>0.0</td>\n",
       "      <td>962.208</td>\n",
       "      <td>96.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>234.5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RFSM</td>\n",
       "      <td>Breathitt</td>\n",
       "      <td>2019-12-10 08:35:00</td>\n",
       "      <td>12.3232</td>\n",
       "      <td>11.7733</td>\n",
       "      <td>0.0</td>\n",
       "      <td>962.406</td>\n",
       "      <td>96.4</td>\n",
       "      <td>0.165164</td>\n",
       "      <td>240.9</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RFSM</td>\n",
       "      <td>Breathitt</td>\n",
       "      <td>2019-12-10 08:40:00</td>\n",
       "      <td>12.2973</td>\n",
       "      <td>11.8885</td>\n",
       "      <td>0.0</td>\n",
       "      <td>962.527</td>\n",
       "      <td>97.3</td>\n",
       "      <td>0.165165</td>\n",
       "      <td>240.4</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RFSM</td>\n",
       "      <td>Breathitt</td>\n",
       "      <td>2019-12-10 08:45:00</td>\n",
       "      <td>12.3016</td>\n",
       "      <td>11.9395</td>\n",
       "      <td>0.0</td>\n",
       "      <td>962.568</td>\n",
       "      <td>97.6</td>\n",
       "      <td>0.165166</td>\n",
       "      <td>230.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "6fda733960c686a6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
